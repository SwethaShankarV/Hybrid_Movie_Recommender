{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945342ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# tame BLAS/OpenMP threaders (macOS Jupyter sometimes crashes otherwise)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae65ed96",
   "metadata": {},
   "source": [
    "#### Step 8: Backend API (FastAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40de58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "faiss.omp_set_num_threads(1)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastapi import FastAPI, HTTPException, Query\n",
    "from pydantic import BaseModel\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # to make the project root importable when notebook lives in here in api/\n",
    "# now this works:\n",
    "from models.ncf_model import NCF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1417049b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS ready: 44383 vectors; dim: 128\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Config / paths ----------------\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().resolve().parents[0]   # points to MovieLens_DL/\n",
    "ART_DIR = ROOT / \"features_artifacts\"\n",
    "CKPT_DIR = ROOT / \"checkpoints\"\n",
    "MAPPINGS_DIR = ROOT / \"mappings\"\n",
    "\n",
    "# contains: emb (N, D), tmdb_id (N,)\n",
    "# If you want base embeddings: \n",
    "EMB_NPZ  = ART_DIR / \"movie_embeddings.npz\" \n",
    "# OR if you want the finetuned embeddings:\n",
    "# EMB_NPZ  = ART_DIR / \"movie_embeddings_finetuned.npz\"   \n",
    " \n",
    "FAISS_IVF = ART_DIR / \"movie_faiss_index_flat.index\"\n",
    "NCF_CKPT = CKPT_DIR / \"ncf_finetuned_final.pt\"\n",
    "U2I_JSON = MAPPINGS_DIR / \"u2i.json\"          # {userId: u_idx}\n",
    "SEEN_PKL = MAPPINGS_DIR / \"user_seen_items.pkl\"  # dict[u_idx] -> set(m_idx)\n",
    "ID2TITLE_JSON = MAPPINGS_DIR / \"id_to_title.json\" # {tmdb_id: title}\n",
    "\n",
    "# Defaults (match your 7D decisions)\n",
    "LOW_HISTORY_MAX_SEEN = 20\n",
    "C_FOR_LOW_USERS = 3.0\n",
    "TOPK_DEFAULT = 20\n",
    "SHORTLIST_M = 200\n",
    "\n",
    "# ---------------- Utilities ----------------\n",
    "def _safe_l2_normalize_rows(mat: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    mat = np.asarray(mat, dtype=np.float32, order=\"C\")\n",
    "    np.nan_to_num(mat, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    norms = np.linalg.norm(mat, axis=1, keepdims=True)\n",
    "    norms = np.maximum(norms, eps)\n",
    "    return mat / norms\n",
    "\n",
    "def _safe_l2_normalize_vec(v: np.ndarray, eps: float = 1e-12) -> np.ndarray:\n",
    "    v = np.asarray(v, dtype=np.float32).reshape(1, -1)\n",
    "    np.nan_to_num(v, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    n = np.linalg.norm(v, axis=1, keepdims=True)\n",
    "    n = np.maximum(n, eps)\n",
    "    return (v / n).astype(np.float32)\n",
    "\n",
    "# ---------------- Load artifacts ----------------\n",
    "npz = np.load(str(EMB_NPZ), allow_pickle=False)\n",
    "\n",
    "# accept either set of keys\n",
    "if \"emb\" in npz and \"tmdb_id\" in npz:\n",
    "    emb = npz[\"emb\"]\n",
    "    ids = npz[\"tmdb_id\"]\n",
    "elif \"movie_embeddings\" in npz and \"tmdb_ids\" in npz:\n",
    "    emb = npz[\"movie_embeddings\"]\n",
    "    ids = npz[\"tmdb_ids\"]\n",
    "else:\n",
    "    raise ValueError(f\"Unrecognized keys in {EMB_NPZ}: {list(npz.keys())}\")\n",
    "\n",
    "movie_embeddings = _safe_l2_normalize_rows(np.asarray(emb))\n",
    "tmdb_ids = np.asarray(ids).astype(np.int64)\n",
    "\n",
    "id_to_row = {int(t): int(i) for i, t in enumerate(tmdb_ids)}\n",
    "# add these two lines:\n",
    "num_items = movie_embeddings.shape[0]\n",
    "emb_dim   = movie_embeddings.shape[1]\n",
    "\n",
    "# id → title map (optional)\n",
    "id_to_title = {}\n",
    "if ID2TITLE_JSON.exists():\n",
    "    with open(str(ID2TITLE_JSON), \"r\", encoding=\"utf-8\") as f:\n",
    "        id_to_title = {int(k): v for k, v in json.load(f).items()}\n",
    "\n",
    "# FAISS\n",
    "# FAISS (build-only in notebook to avoid write crashes)\n",
    "d = movie_embeddings.shape[1]\n",
    "if FAISS_IVF.exists():\n",
    "    try:\n",
    "        faiss_index = faiss.read_index(str(FAISS_IVF))\n",
    "        if faiss_index.d != d:\n",
    "            print(f\"[WARN] FAISS index dim {faiss_index.d} != emb dim {d}. Rebuilding (no write).\")\n",
    "            faiss_index = faiss.IndexFlatIP(d)\n",
    "            faiss_index.add(movie_embeddings.astype(\"float32\"))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to read saved FAISS index: {e}. Rebuilding (no write).\")\n",
    "        faiss_index = faiss.IndexFlatIP(d)\n",
    "        faiss_index.add(movie_embeddings.astype(\"float32\"))\n",
    "else:\n",
    "    faiss_index = faiss.IndexFlatIP(d)\n",
    "    faiss_index.add(movie_embeddings.astype(\"float32\"))\n",
    "\n",
    "print(\"FAISS ready:\", faiss_index.ntotal, \"vectors; dim:\", d)\n",
    "\n",
    "# user mappings\n",
    "u2i = {}\n",
    "if U2I_JSON.exists():\n",
    "    with open(str(U2I_JSON), \"r\", encoding=\"utf-8\") as f:\n",
    "        tmp = json.load(f)\n",
    "        # keys may be str; normalizing\n",
    "        u2i = {int(k): int(v) for k, v in tmp.items()}\n",
    "\n",
    "user_seen_items = {}\n",
    "if SEEN_PKL.exists():\n",
    "    with open(str(SEEN_PKL), \"rb\") as f:\n",
    "        user_seen_items = pickle.load(f)  # dict[u_idx] -> set(m_idx)\n",
    "        # normalize to sets of int\n",
    "        user_seen_items = {int(u): set(int(m) for m in s) for u, s in user_seen_items.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81601687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Safe checkpoint load (CPU first, strict shapes, then optional GPU move) ----\n",
    "import os, gc, torch\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# 0) Force CPU for load to avoid CUDA init crashes\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ckpt_device = \"cpu\"   # always load on CPU first\n",
    "\n",
    "# 1) Load state dict safely\n",
    "state = torch.load(str(NCF_CKPT), map_location=ckpt_device)\n",
    "# Some checkpoints wrap weights under 'state_dict'\n",
    "if isinstance(state, dict) and \"state_dict\" in state:\n",
    "    state = state[\"state_dict\"]\n",
    "\n",
    "# 2) Infer sizes from checkpoint (do NOT touch GPU yet)\n",
    "n_users_ckpt = state[\"user_emb.weight\"].shape[0]\n",
    "n_items_ckpt = state[\"item_emb.weight\"].shape[0]\n",
    "emb_dim_ckpt = state[\"item_emb.weight\"].shape[1]\n",
    "\n",
    "# 3) Build model to EXACT checkpoint sizes, on CPU, with no external init\n",
    "model = NCF(\n",
    "    num_users=n_users_ckpt,\n",
    "    num_items=n_items_ckpt,\n",
    "    emb_dim=emb_dim_ckpt,\n",
    "    init_item_vectors=None,\n",
    "    freeze_items=False\n",
    ").cpu()\n",
    "\n",
    "# 4) Strict load — if this crashes, the file is likely corrupted/incompatible\n",
    "missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "if missing or unexpected:\n",
    "    print(\"[INFO] load_state_dict non-strict:\", {\"missing\": missing, \"unexpected\": unexpected})\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 5) Optional: if your current movie_embeddings align in BOTH count and dim, you can override item vectors\n",
    "n_items_cur, emb_dim_cur = movie_embeddings.shape\n",
    "if n_items_cur == n_items_ckpt and emb_dim_cur == emb_dim_ckpt:\n",
    "    with torch.no_grad():\n",
    "        # replace item_emb table with your current content embeddings\n",
    "        model.item_emb.weight.data.copy_(torch.from_numpy(movie_embeddings))\n",
    "\n",
    "# 6) Optional: only now move to GPU, after everything is stable on CPU\n",
    "if device == \"cuda\":\n",
    "    model = model.to(\"cuda\")\n",
    "\n",
    "# 7) Guard: ensure u2i fits the checkpoint’s user table\n",
    "if u2i and max(u2i.values()) >= n_users_ckpt:\n",
    "    raise RuntimeError(\n",
    "        f\"u2i max index {max(u2i.values())} >= checkpoint user_emb size {n_users_ckpt}. \"\n",
    "        \"Use the same split mapping you trained with or retrain.\"\n",
    "    )\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c90ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Core helpers ----------------\n",
    "def build_user_profile_mean(u_idx: int) -> Optional[np.ndarray]:\n",
    "    seen = list(user_seen_items.get(u_idx, set()))\n",
    "    if not seen:\n",
    "        return None\n",
    "    prof = movie_embeddings[seen].mean(axis=0)\n",
    "    n = np.linalg.norm(prof)\n",
    "    if n == 0:\n",
    "        return None\n",
    "    return (prof / n).astype(np.float32)\n",
    "\n",
    "def shortlist_by_content_seed(seed_tmdb_id: int, M: int = SHORTLIST_M) -> np.ndarray:\n",
    "    pos = id_to_row.get(int(seed_tmdb_id))\n",
    "    if pos is None:\n",
    "        raise KeyError(f\"TMDB id {seed_tmdb_id} not found.\")\n",
    "    q = _safe_l2_normalize_vec(movie_embeddings[pos])\n",
    "    sims, idxs = faiss_index.search(q, M)\n",
    "    idxs = idxs[0]\n",
    "    idxs = idxs[idxs != pos]  # drop self\n",
    "    return idxs.astype(np.int32, copy=False)\n",
    "\n",
    "def shortlist_by_content_for_user(u_idx: int, M: int = SHORTLIST_M) -> np.ndarray:\n",
    "    prof = build_user_profile_mean(u_idx)\n",
    "    seen = user_seen_items.get(u_idx, set())\n",
    "    if prof is None:\n",
    "        # simple fallback: first unseen M\n",
    "        if len(seen) >= num_items:\n",
    "            return np.array([], dtype=np.int32)\n",
    "        idxs = [i for i in range(num_items) if i not in seen][:M]\n",
    "        return np.array(idxs, dtype=np.int32)\n",
    "    q = _safe_l2_normalize_vec(prof)\n",
    "    sims, idxs = faiss_index.search(q, M)\n",
    "    idxs = idxs[0]\n",
    "    idxs = np.array([i for i in idxs if i not in seen], dtype=np.int32)\n",
    "    return idxs\n",
    "\n",
    "@torch.no_grad()\n",
    "def ncf_score_user_array(u_idx: int, item_idxs: np.ndarray, batch: int = 4096) -> np.ndarray:\n",
    "    out = []\n",
    "    u_t = torch.tensor([u_idx], dtype=torch.long, device=device)\n",
    "    for i in range(0, len(item_idxs), batch):\n",
    "        chunk = item_idxs[i:i+batch]\n",
    "        uu = u_t.repeat(len(chunk))\n",
    "        mm = torch.tensor(chunk, dtype=torch.long, device=device)\n",
    "        logits = model(uu, mm).detach().cpu().numpy().astype(np.float32)\n",
    "        out.append(logits)\n",
    "    return np.concatenate(out, axis=0)\n",
    "\n",
    "def hybrid_for_user(u_idx: int, item_idxs: np.ndarray, C: float = C_FOR_LOW_USERS):\n",
    "    # z-score normalize per user (your original variant)\n",
    "    prof = build_user_profile_mean(u_idx)\n",
    "    if prof is None:\n",
    "        c_scores = np.zeros(len(item_idxs), dtype=np.float32)\n",
    "    else:\n",
    "        c_scores = (movie_embeddings[item_idxs] @ prof).astype(np.float32)\n",
    "    cf_scores = ncf_score_user_array(u_idx, item_idxs)\n",
    "\n",
    "    def z(x):\n",
    "        m, s = x.mean(), x.std()\n",
    "        return (x - m) / (s + 1e-9) if s > 0 else x * 0.0\n",
    "\n",
    "    c2 = z(c_scores)\n",
    "    cf2 = z(cf_scores)\n",
    "\n",
    "    n_seen = len(user_seen_items.get(u_idx, set()))\n",
    "    alpha = min(1.0, C / (C + max(0, n_seen)))  # alpha_by_num_ratings\n",
    "    scores = alpha * c2 + (1.0 - alpha) * cf2\n",
    "    return scores.astype(np.float32), alpha\n",
    "\n",
    "def pack_items(item_idxs: np.ndarray, scores: Optional[np.ndarray] = None):\n",
    "    out = []\n",
    "    for i, idx in enumerate(item_idxs.tolist()):\n",
    "        tmdb = int(tmdb_ids[idx])\n",
    "        out.append({\n",
    "            \"tmdb_id\": tmdb,\n",
    "            \"title\": id_to_title.get(tmdb, None),\n",
    "            **({\"score\": float(scores[i])} if scores is not None else {})\n",
    "        })\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975337ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- FastAPI ----------------\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "app = FastAPI(title=\"Hybrid Recommender API\", version=\"1.0.0\")\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],          # during dev; tighten later\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "class RecResponse(BaseModel):\n",
    "    items: List[dict]\n",
    "    alpha: Optional[float] = None\n",
    "    used_shortlist_M: Optional[int] = None\n",
    "    k: int\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"ok\", \"users\": len(u2i), \"items\": int(movie_embeddings.shape[0]), \"dim\": int(movie_embeddings.shape[1]), \"sample_user_ids\": list(list(u2i.keys())[:5])}\n",
    "\n",
    "@app.get(\"/recommend_by_movie\", response_model=RecResponse)\n",
    "def recommend_by_movie(tmdb_id: int, k: int = Query(TOPK_DEFAULT, ge=1, le=100), M: int = SHORTLIST_M):\n",
    "    try:\n",
    "        idxs = shortlist_by_content_seed(tmdb_id, M=M)[:k]\n",
    "    except KeyError as e:\n",
    "        raise HTTPException(status_code=404, detail=str(e))\n",
    "    return RecResponse(items=pack_items(idxs), alpha=1.0, used_shortlist_M=M, k=k)\n",
    "\n",
    "@app.get(\"/recommend_for_user\", response_model=RecResponse)\n",
    "def recommend_for_user(user_id: int, k: int = Query(TOPK_DEFAULT, ge=1, le=100), M: int = SHORTLIST_M):\n",
    "    if user_id not in u2i:\n",
    "        raise HTTPException(status_code=404, detail=f\"user_id {user_id} not found\")\n",
    "    u_idx = u2i[user_id]\n",
    "    shortlist = shortlist_by_content_for_user(u_idx, M=M)\n",
    "    if shortlist.size == 0:\n",
    "        return RecResponse(items=[], alpha=None, used_shortlist_M=M, k=k)\n",
    "    # **Collaborative-only**: rank shortlist by NCF logits\n",
    "    scores = ncf_score_user_array(u_idx, shortlist)\n",
    "    order = np.argsort(-scores)[:k]\n",
    "    topk = shortlist[order]\n",
    "    return RecResponse(items=pack_items(topk, scores[order]), alpha=None, used_shortlist_M=M, k=k)\n",
    "\n",
    "@app.get(\"/recommend_hybrid\", response_model=RecResponse)\n",
    "def recommend_hybrid(user_id: int, tmdb_id: Optional[int] = None,\n",
    "                     k: int = Query(TOPK_DEFAULT, ge=1, le=100),\n",
    "                     M: int = SHORTLIST_M, C: float = C_FOR_LOW_USERS):\n",
    "    if tmdb_id is not None:\n",
    "        # seed-based content path\n",
    "        idxs = shortlist_by_content_seed(tmdb_id, M=M)[:k]\n",
    "        return RecResponse(items=pack_items(idxs), alpha=1.0, used_shortlist_M=M, k=k)\n",
    "\n",
    "    if user_id not in u2i:\n",
    "        raise HTTPException(status_code=404, detail=f\"user_id {user_id} not found\")\n",
    "    u_idx = u2i[user_id]\n",
    "    shortlist = shortlist_by_content_for_user(u_idx, M=M)\n",
    "    if shortlist.size == 0:\n",
    "        return RecResponse(items=[], alpha=None, used_shortlist_M=M, k=k)\n",
    "    scores, alpha = hybrid_for_user(u_idx, shortlist, C=C)\n",
    "    order = np.argsort(-scores)[:k]\n",
    "    topk = shortlist[order]\n",
    "    return RecResponse(items=pack_items(topk, scores[order]), alpha=float(alpha), used_shortlist_M=M, k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [69119]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51147 - \"GET /health HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51147 - \"GET /recommend_by_movie?tmdb_id=862&k=12 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51147 - \"GET /recommend_for_user?user_id=1&k=12 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51147 - \"GET /recommend_hybrid?user_id=1&k=12&M=200&C=3.0 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52386 - \"GET /recommend_by_movie?tmdb_id=862&k=12 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52386 - \"GET /health HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52386 - \"GET /recommend_for_user?user_id=1&k=12 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52386 - \"GET /recommend_hybrid?user_id=1&k=12&M=200&C=3.0 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52406 - \"GET /health HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52406 - \"GET /recommend_by_movie?tmdb_id=862&k=12 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52406 - \"GET /recommend_for_user?user_id=1&k=12 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52406 - \"GET /recommend_hybrid?user_id=1&k=12&M=200&C=3.0 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54123 - \"GET /health HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54126 - \"GET /recommend_by_movie?tmdb_id=862&k=12 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54129 - \"GET /recommend_for_user?user_id=1&k=10 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54131 - \"GET /recommend_hybrid?user_id=1&k=12&M=200&C=3.0 HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "import threading, uvicorn, nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def _run():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, reload=False, log_level=\"info\")\n",
    "\n",
    "t = threading.Thread(target=_run, daemon=True)\n",
    "t.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e006de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be1c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movielens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
